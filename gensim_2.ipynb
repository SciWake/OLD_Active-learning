{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d22e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.fasttext import FastText, load_facebook_model\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f0646d-b57e-47c2-ad7f-ae1bb9bdec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade gensim==4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b0055e0-d220-42f0-98c3-2311a44dd208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gensim\n",
      "Version: 4.2.0\n",
      "Summary: Python framework for fast Vector Space Modelling\n",
      "Home-page: http://radimrehurek.com/gensim\n",
      "Author: Radim Rehurek\n",
      "Author-email: me@radimrehurek.com\n",
      "License: LGPL-2.1-only\n",
      "Location: c:\\users\\bimas\\anaconda3\\lib\\site-packages\n",
      "Requires: scipy, numpy, Cython, smart-open\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970cc676",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1dc89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback(CallbackAny2Vec):\n",
    "    '''Callback for Word2vec with resetting loss on the end of each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "\n",
    "        self.epoch = 1\n",
    "        self.losses = []\n",
    "        self.cumu_loss = 0.0\n",
    "        self.previous_epoch_time = time.time()\n",
    "\n",
    "        self.best_model = None\n",
    "        self.best_loss = 1e+30\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "\n",
    "        norms = [np.linalg.norm(v) for v in model.wv.vectors]\n",
    "        now = time.time()\n",
    "        epoch_seconds = now - self.previous_epoch_time\n",
    "        self.previous_epoch_time = now\n",
    "        self.cumu_loss += float(loss)\n",
    "        print(f\"Loss after epoch {self.epoch}: {loss} (cumulative loss so far: {self.cumu_loss}) \"+\\\n",
    "              f\"-> epoch took {round(epoch_seconds, 2)} s - vector norms min/avg/max: \"+\\\n",
    "              f\"{round(float(min(norms)), 2)}, {round(float(sum(norms)/len(norms)), 2)}, {round(float(max(norms)), 2)}\")\n",
    "        self.epoch += 1\n",
    "\n",
    "        self.losses.append(float(loss))\n",
    "        \n",
    "        # reset loss inside model\n",
    "        model.running_training_loss = 0.0\n",
    "\n",
    "        if loss < self.best_loss:\n",
    "            self.best_model = copy.deepcopy(model)\n",
    "            self.best_loss = loss\n",
    "\n",
    "        if self.epoch % 5 == 0:\n",
    "            self.plot(path=\"w2v_training_loss.png\")\n",
    "\n",
    "    def plot(self, path):\n",
    "        fig, (ax1) = plt.subplots(ncols=1, figsize=(6, 6))\n",
    "        ax1.plot(self.losses, label=\"loss per epoch\")\n",
    "        plt.legend()\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "        print(\"Plotted loss.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e36dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss - self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578ee8d",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_facebook_model('cc.ru.300.bin')\n",
    "model = FastText.load_fasttext_format('wiki.ru.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc8bba",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58b4d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building vocabulary...\n"
     ]
    }
   ],
   "source": [
    "print(\"building vocabulary...\")\n",
    "model.build_vocab(sentence_corpus[:500], update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3d7ae1c-e7cf-4189-8d23-a995420df866",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Word2Vec...\n",
      "Loss after epoch 0: 0.0\n",
      "Loss after epoch 1: 0.0\n",
      "Loss after epoch 2: 0.0\n",
      "Loss after epoch 3: 0.0\n",
      "Loss after epoch 4: 0.0\n",
      "Loss after epoch 5: 0.0\n",
      "Loss after epoch 6: 0.0\n",
      "Loss after epoch 7: 0.0\n",
      "Loss after epoch 8: 0.0\n",
      "Loss after epoch 9: 0.0\n",
      "Loss after epoch 10: 0.0\n",
      "Loss after epoch 11: 0.0\n",
      "Loss after epoch 12: 0.0\n",
      "Loss after epoch 13: 0.0\n",
      "Loss after epoch 14: 0.0\n",
      "Loss after epoch 15: 0.0\n",
      "Loss after epoch 16: 0.0\n",
      "Loss after epoch 17: 0.0\n",
      "Loss after epoch 18: 0.0\n",
      "Loss after epoch 19: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\bimas\\AppData\\Local\\Temp/ipykernel_4996/1605362792.py\", line 3, in <module>\n",
      "    model.train(\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\", line 1083, in train\n",
      "    self._clear_post_train()\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\", line 460, in _clear_post_train\n",
      "    self.wv.adjust_vectors()  # ensure composite-word vecs reflect latest training\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\", line 1181, in adjust_vectors\n",
      "    self.vectors[i] += self.vectors_ngrams[nh]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\bimas\\anaconda3\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4996/1605362792.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcallbacker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.train(\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0msentence_corpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# number of times train() has been called\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_post_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36m_clear_post_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFastText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_post_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjust_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# ensure composite-word vecs reflect latest training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36madjust_vectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mnh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mngram_buckets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1181\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_ngrams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1182\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_buckets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2063\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "print(\"training Word2Vec...\")\n",
    "callbacker = callback()\n",
    "model.train(\n",
    "        sentence_corpus[:500],\n",
    "#         epochs=model.iter,\n",
    "        epochs=20,        \n",
    "    total_examples=model.corpus_count,\n",
    "        compute_loss=True,\n",
    "        callbacks=[callbacker]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e277449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef3695fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee —Ö–æ—Ç—å —è –∏ —à–∫–æ–ª–æ—Ç–∞, –Ω–æ –ø–æ–≤–µ—Ä—å, —É –Ω–∞...</td>\n",
       "      <td>positive</td>\n",
       "      <td>first_timee —Ö–æ—Ç—å —è –∏ —à–∫–æ–ª–æ—Ç—ã–π –Ω–æ –ø–æ–≤–µ—Ä—å —É –º—ã —Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–î–∞, –≤—Å–µ-—Ç–∞–∫–∏ –æ–Ω –Ω–µ–º–Ω–æ–≥–æ –ø–æ—Ö–æ–∂ –Ω–∞ –Ω–µ–≥–æ. –ù–æ –º–æ–π ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>–¥–∞ –≤—Å—ë —Ç–∞–∫–∏ –æ–Ω –Ω–µ–º–Ω–æ–≥–æ –ø–æ—Ö–æ–∂–∏–π –Ω–∞ –æ–Ω –Ω–æ –º–æ–π –º–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: –ù—É —Ç—ã –∏–¥–∏–æ—Ç–∫–∞) —è –∏—Å–ø—É–≥–∞–ª–∞—Å—å –∑–∞ ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>rt katiacheh: –Ω—É —Ç—ã –∏–¥–∏–æ—Ç–∫–∞) —è –∏—Å–ø—É–≥–∞—Ç—å—Å—è –∑–∞ —Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"–ö—Ç–æ —Ç–æ –≤ —É–≥–ª—É —Å–∏–¥–∏—Ç –∏ –ø–æ–≥–∏–±–∞–µ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>rt digger : –∫—Ç–æ —Ç–æ –≤ —É–≥–æ–ª —Å–∏–¥–µ—Ç—å –∏ –ø–æ–≥–∏–±–∞—Ç—å –æ—Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant –í–æ—Ç —á—Ç–æ –∑–Ω–∞—á–∏—Ç —Å—Ç—Ä–∞—à–∏–ª–∫–∞ :D\\n–ù...</td>\n",
       "      <td>positive</td>\n",
       "      <td>irina_dyshkant –≤–æ—Ç —á—Ç–æ –∑–Ω–∞—á–∏—Ç —Å—Ç—Ä–∞—à–∏–ª–∫–∞ :d –Ω–æ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0  @first_timee —Ö–æ—Ç—å —è –∏ —à–∫–æ–ª–æ—Ç–∞, –Ω–æ –ø–æ–≤–µ—Ä—å, —É –Ω–∞...  positive   \n",
       "1  –î–∞, –≤—Å–µ-—Ç–∞–∫–∏ –æ–Ω –Ω–µ–º–Ω–æ–≥–æ –ø–æ—Ö–æ–∂ –Ω–∞ –Ω–µ–≥–æ. –ù–æ –º–æ–π ...  positive   \n",
       "2  RT @KatiaCheh: –ù—É —Ç—ã –∏–¥–∏–æ—Ç–∫–∞) —è –∏—Å–ø—É–≥–∞–ª–∞—Å—å –∑–∞ ...  positive   \n",
       "3  RT @digger2912: \"–ö—Ç–æ —Ç–æ –≤ —É–≥–ª—É —Å–∏–¥–∏—Ç –∏ –ø–æ–≥–∏–±–∞–µ...  positive   \n",
       "4  @irina_dyshkant –í–æ—Ç —á—Ç–æ –∑–Ω–∞—á–∏—Ç —Å—Ç—Ä–∞—à–∏–ª–∫–∞ :D\\n–ù...  positive   \n",
       "\n",
       "                                              lemmas  \n",
       "0  first_timee —Ö–æ—Ç—å —è –∏ —à–∫–æ–ª–æ—Ç—ã–π –Ω–æ –ø–æ–≤–µ—Ä—å —É –º—ã —Ç...  \n",
       "1  –¥–∞ –≤—Å—ë —Ç–∞–∫–∏ –æ–Ω –Ω–µ–º–Ω–æ–≥–æ –ø–æ—Ö–æ–∂–∏–π –Ω–∞ –æ–Ω –Ω–æ –º–æ–π –º–∞...  \n",
       "2  rt katiacheh: –Ω—É —Ç—ã –∏–¥–∏–æ—Ç–∫–∞) —è –∏—Å–ø—É–≥–∞—Ç—å—Å—è –∑–∞ —Ç...  \n",
       "3  rt digger : –∫—Ç–æ —Ç–æ –≤ —É–≥–æ–ª —Å–∏–¥–µ—Ç—å –∏ –ø–æ–≥–∏–±–∞—Ç—å –æ—Ç...  \n",
       "4  irina_dyshkant –≤–æ—Ç —á—Ç–æ –∑–Ω–∞—á–∏—Ç —Å—Ç—Ä–∞—à–∏–ª–∫–∞ :d –Ω–æ ...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('twitter.zip')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "703a4a2e-3f6b-498e-a46f-1963bf152748",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = [sg_model.get_sentence_vector(line) for line in data[\"lemmas\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23d424dd-a462-4c15-922b-7cf126c74405",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1 if label == 'positive' else 0 for label in data['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56681e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels) == len(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "69078609-26f8-46ff-acbd-a7b3744ab26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65538228",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(emb, labels, test_size=0.3, shuffle=True, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "693b5647-3867-4c4f-b7fb-394ae8809401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(n_jobs=-1)\n",
    "lr.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ebf55906-52aa-4f6f-b524-3fb42f7f1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca87c543-c70f-48be-85ca-cd6214801634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression ROC-AUC: 0.84378918855271\n"
     ]
    }
   ],
   "source": [
    "lr_pred = lr.decision_function(test_data)\n",
    "print('Logistic regression ROC-AUC:', roc_auc_score(test_labels, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d4f0e-142b-4fbb-ac5e-b281c647feab",
   "metadata": {},
   "source": [
    "# –î–æ–æ–±—É—á–µ–Ω–∏–µ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b6237b-a162-448e-8ea5-19b2e8aee517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b20e1a-0914-4e2f-b879-09986767038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sg_model = fasttext.train_unsupervised(input='perfumery.txt', dim=300, lr=0.6, word_ngrams=3, pretrainedVectors='cc.ru.300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4726f1ea-166a-41af-b0a9-1e4e9b63fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip', archive_name='perfumery.zip')  \n",
    "tables.to_csv('perfumery.zip', index=False, compression=compression_opts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffc071da-cbd3-4119-bebb-ea5e6f2c3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/processed/perfumery.txt\", \"w\", encoding='UTF-8') as file:\n",
    "    for line in tables.comment_text.values:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71daa415-652b-4560-b64d-b67d13856e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised(input='perfumery.txt', dim=300, lr=0.07, word_ngrams=3, pretrainedVectors='cc.ru.300.vec', bucket=300000, lrUpdateRate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0c026-f313-4988-a46b-814e9a3ef679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169b3c8-c6c8-4860-84a6-5cb18ac6c898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19667161-9583-4b8c-9384-3a96fb292d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1651335b-dfca-48d9-8c6b-ca2538314dba",
   "metadata": {},
   "source": [
    "<h1 align='center'>–î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dfa3178-b949-49ee-861f-ac5e536792df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from gensim.models.fasttext import FastText, load_facebook_model\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from functools import lru_cache\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b95e6-f7e9-40d8-9044-b112a7684a45",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1a45d4a-a999-4fca-9e45-357335aec879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaPredictText:\n",
    "    pymorphy = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    def __init__(self, regex: str = \"[–ê-–Ø–Å–∞-—è—ë]+\"):\n",
    "        self.regex = re.compile(regex)\n",
    "\n",
    "    def words_only(self, text: str) -> list:\n",
    "        try:\n",
    "            return self.regex.findall(text.lower())\n",
    "        except AttributeError:\n",
    "            return []\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_stopwords(words, stopwords = stopw):\n",
    "        return [w for w in words if not w in stopwords and len(w) > 3]\n",
    "\n",
    "    # @lru_cache(maxsize=128)\n",
    "    def lemma(self, text: list) -> str:\n",
    "        try:\n",
    "            return \" \".join([self.pymorphy.parse(w)[0].normal_form for w in text])\n",
    "        except AttributeError:\n",
    "            return \" \"\n",
    "\n",
    "    def clean_text(self, text, lemma=True):\n",
    "        remove = self.remove_stopwords(self.words_only(text))\n",
    "        if lemma:\n",
    "            return self.lemma(remove)\n",
    "        return \" \".join(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24a8f872-1b97-43fa-8e68-47b561332a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–°—Ä–∞–∑—É —Å–∫–∞–∂—É, —á—Ç–æ –∞—Ä–æ–º–∞—Ç –Ω–∞ –ª—é–±–∏—Ç–µ–ª—è. –ù–æ –º–µ–Ω—è –æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–∫–æ–≥–¥–∞ –º–Ω–µ –¥–∞–ª–∏ –ø–æ—Å–ª—É—à–∞—Ç—å —ç—Ç–æ—Ç –∞—Ä–æ–º–∞—Ç, –º–Ω–µ —Ç–∞–∫ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –ø–∞—Ä–∞ –∫ –∂–µ–Ω—Å–∫–æ–π –Ω–æ–≤–∏–Ω–∫–µ —ç—Ç–æ–π –º–∞—Ä–∫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π —Ñ—Ä—É–∫—Ç–æ–≤—ã–π –∞—Ä–æ–º–∞—Ç!üçä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–û—á–µ–Ω—å –∫–ª–∞—Å—Å–Ω—ã–π –Ω–∞–±–æ—Ä, –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ–π–¥—ë—Ç –Ω–∞ –ø–æ–¥–∞...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text\n",
       "0  –°—Ä–∞–∑—É —Å–∫–∞–∂—É, —á—Ç–æ –∞—Ä–æ–º–∞—Ç –Ω–∞ –ª—é–±–∏—Ç–µ–ª—è. –ù–æ –º–µ–Ω—è –æ...\n",
       "1  –∫–æ–≥–¥–∞ –º–Ω–µ –¥–∞–ª–∏ –ø–æ—Å–ª—É—à–∞—Ç—å —ç—Ç–æ—Ç –∞—Ä–æ–º–∞—Ç, –º–Ω–µ —Ç–∞–∫ ...\n",
       "2  –ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –ø–∞—Ä–∞ –∫ –∂–µ–Ω—Å–∫–æ–π –Ω–æ–≤–∏–Ω–∫–µ —ç—Ç–æ–π –º–∞—Ä–∫...\n",
       "3                        –û—Ç–ª–∏—á–Ω—ã–π —Ñ—Ä—É–∫—Ç–æ–≤—ã–π –∞—Ä–æ–º–∞—Ç!üçä\n",
       "4  –û—á–µ–Ω—å –∫–ª–∞—Å—Å–Ω—ã–π –Ω–∞–±–æ—Ä, –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ–π–¥—ë—Ç –Ω–∞ –ø–æ–¥–∞..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/input/perfumery.zip')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04e5048c-f929-4907-bce2-d49e35d68f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'—Å—Ä–∞–∑—É —Å–∫–∞–∑–∞—Ç—å –∞—Ä–æ–º–∞—Ç –ª—é–±–∏—Ç–µ–ª—å –ø–æ–∫–æ—Ä–∏—Ç—å —Å—Ç–æ–π–∫–∏–π –≤–µ—Å—å–º–∞ –≥—Ä–æ–º–∫–∏–π –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear = LemmaPredictText()\n",
    "clear.clean_text(data['comment_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d193366-5e3d-4360-baec-d4c5f8fda1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text_lemma.txt\", \"w\", encoding='UTF-8') as file:\n",
    "    for line in data['comment_text']:\n",
    "        file.write(clear.clean_text(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11c2fe-a9b8-4827-825d-14114cece401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
