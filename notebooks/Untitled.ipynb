{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9275c933-3275-4917-85e9-6512fd297a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8cafd8-044f-4614-a333-476eb9d12c3f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86fc8cf5-954d-484b-bb38-5fe119cf171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–°—Ä–∞–∑—É —Å–∫–∞–∂—É, —á—Ç–æ –∞—Ä–æ–º–∞—Ç –Ω–∞ –ª—é–±–∏—Ç–µ–ª—è. –ù–æ –º–µ–Ω—è –æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–∫–æ–≥–¥–∞ –º–Ω–µ –¥–∞–ª–∏ –ø–æ—Å–ª—É—à–∞—Ç—å —ç—Ç–æ—Ç –∞—Ä–æ–º–∞—Ç, –º–Ω–µ —Ç–∞–∫ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –ø–∞—Ä–∞ –∫ –∂–µ–Ω—Å–∫–æ–π –Ω–æ–≤–∏–Ω–∫–µ —ç—Ç–æ–π –º–∞—Ä–∫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π —Ñ—Ä—É–∫—Ç–æ–≤—ã–π –∞—Ä–æ–º–∞—Ç!üçä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–û—á–µ–Ω—å –∫–ª–∞—Å—Å–Ω—ã–π –Ω–∞–±–æ—Ä, –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ–π–¥—ë—Ç –Ω–∞ –ø–æ–¥–∞...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text\n",
       "0  –°—Ä–∞–∑—É —Å–∫–∞–∂—É, —á—Ç–æ –∞—Ä–æ–º–∞—Ç –Ω–∞ –ª—é–±–∏—Ç–µ–ª—è. –ù–æ –º–µ–Ω—è –æ...\n",
       "1  –∫–æ–≥–¥–∞ –º–Ω–µ –¥–∞–ª–∏ –ø–æ—Å–ª—É—à–∞—Ç—å —ç—Ç–æ—Ç –∞—Ä–æ–º–∞—Ç, –º–Ω–µ —Ç–∞–∫ ...\n",
       "2  –ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –ø–∞—Ä–∞ –∫ –∂–µ–Ω—Å–∫–æ–π –Ω–æ–≤–∏–Ω–∫–µ —ç—Ç–æ–π –º–∞—Ä–∫...\n",
       "3                        –û—Ç–ª–∏—á–Ω—ã–π —Ñ—Ä—É–∫—Ç–æ–≤—ã–π –∞—Ä–æ–º–∞—Ç!üçä\n",
       "4  –û—á–µ–Ω—å –∫–ª–∞—Å—Å–Ω—ã–π –Ω–∞–±–æ—Ä, –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ–π–¥—ë—Ç –Ω–∞ –ø–æ–¥–∞..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/input/perfumery.zip')\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c481c4c-dfc9-452a-b78a-0a18ea6784f9",
   "metadata": {},
   "source": [
    "### Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149ba278-3c63-4033-925d-61181fd3a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\"[–ê-–Ø–Å–∞-—è—ëA-z]+\")\n",
    "mystopwords = stopwords.words(fileids='russian')\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 1]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    return ' '.join(remove_stopwords(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1007c1b-621d-470b-b5ca-f5316cd06d75",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving a set for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19140814-2881-4f60-beeb-ed892fd79979",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"p.txt\", \"w\", encoding='UTF-8') as file:\n",
    "    for line in data.comment_text.values:\n",
    "        if len(line) > 300:\n",
    "            file.write(clean_text(line) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2a18e-e8df-4fdb-981f-bbba595dc798",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8bd5612-9339-4d84-aa3d-c341b1c1c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original BIN model loading\n",
    "model = fasttext.load_model(\"model/adaptation/perfumery.bin\")\n",
    "lines = []\n",
    "\n",
    "# get all words from model\n",
    "words = model.get_words()\n",
    "\n",
    "with open('model.vec','w') as file_out:\n",
    "    \n",
    "    # the first line must contain number of total words and vector dimension\n",
    "    file_out.write(str(len(words)) + \" \" + str(model.get_dimension()) + \"\\n\")\n",
    "\n",
    "    # line by line, you append vectors to VEC file\n",
    "    for w in words:\n",
    "        v = model.get_word_vector(w)\n",
    "        vstr = \"\"\n",
    "        for vi in v:\n",
    "            vstr += \" \" + str(vi)\n",
    "        try:\n",
    "            file_out.write(w + vstr+'\\n')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fa25c6-a081-444f-a4da-658e48bdc4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69947a9-d091-435c-897c-5c6df6a61acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model(\"model/adaptation/perfumery_epoch_1.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ed2df3-8b7e-4ef2-9ed6-c4f6f9df3b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building vocabulary...\n"
     ]
    }
   ],
   "source": [
    "print(\"building vocabulary...\")\n",
    "model.build_vocab('perfumery.txt', update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa506f0-12e5-4d41-a116-304eb01746db",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c3f541-1828-4d77-a1be-3e6aeb8e36b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–ø–∞—Ä—Ñ—é–º—ã', 0.7377110123634338),\n",
       " ('–∞—Ä–æ–º–∞—Ç', 0.7371137142181396),\n",
       " ('–ø–∞—Ä—Ñ—é–º–µ—Ä–Ω—ã–π', 0.7119106650352478),\n",
       " ('–ü–∞—Ä—Ñ—é–º', 0.7044569849967957),\n",
       " ('–ø–∞—Ä—Ñ—é–º.', 0.6883740425109863),\n",
       " ('–ø–∞—Ä—Ñ—é–º–∞', 0.6814783811569214),\n",
       " ('–¥—É—Ö–∏', 0.6683558821678162),\n",
       " ('–¥–µ–∑–æ–¥–æ—Ä–∞–Ω—Ç', 0.6603888273239136),\n",
       " ('–ø–∞—Ä—Ñ—é–º–æ–≤', 0.6553675532341003),\n",
       " ('–ø–∞—Ä—Ñ—É–º', 0.6519331336021423)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('–ø–∞—Ä—Ñ—é–º')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8778029f-ecd9-49d3-bc89-dde76023f939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–ì—É–º–∞–Ω–∏—Ç–∞—Ä–Ω–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π', 0.561374306678772),\n",
       " ('–º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä—ã—É—á–µ–±–Ω–æ-–º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–π', 0.5601953268051147),\n",
       " ('–í—Ä–∞—á–µ–±–Ω–æ-—Ñ–∏–∑–∫—É–ª—å—Ç—É—Ä–Ω—ã–π', 0.5565395355224609),\n",
       " ('–∞–≥—Ä–∞—Ä–Ω–æ-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π', 0.5547544360160828),\n",
       " ('—Ä–µ–≤–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π', 0.5517967343330383),\n",
       " ('–ì—É–º–∞–Ω–∏—Ç–∞—Ä–Ω–æ-–ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–π', 0.5509157180786133),\n",
       " ('–∫–∞—Ä–¥–∏–æ—Ä–µ–≤–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π', 0.5496220588684082),\n",
       " ('–ø–µ–∫—Ç–∏–Ω—è–±–ª–æ—á–Ω—ã–π', 0.5401729941368103),\n",
       " ('–∞–≥—Ä–∞—Ä–Ω–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π', 0.5355527997016907),\n",
       " ('–∏—Å—Ç–æ—Ä–∏–∫–æ-–∫—É–ª—å—Ç—É—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π', 0.5343062877655029)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('—Ñ—É—Ä—É–∫—Ç–æ–≤—ã–π')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043ba54-e391-4a7e-b5bc-2e18cda44423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
